# LLM Finetuning and Pretraining with Unsloth AI  
This repository contains a comprehensive set of Colab notebooks demonstrating the fine-tuning, continued pretraining, reward modeling, and reasoning of various open-weight LLMs using **Unsloth AI**. The project covers multiple use cases, including coding, chat, mental health chatbots, and exporting to Ollama.  

---

## ğŸš€ **Why This Project is Important**  
Large Language Models (LLMs) have become a foundational technology for a wide range of applications, including natural language processing, conversational AI, and coding assistance. However, deploying and optimizing these models for real-world scenarios requires **fine-tuning** and **continued pretraining** to adapt them to specific tasks and datasets.  

This project leverages **Unsloth AI** to simplify and accelerate the process of fine-tuning and pretraining LLMs. Unsloth AI provides a lightweight, efficient framework for working with LLMs, reducing memory consumption and speeding up the training process. The use cases in this repository cover a diverse range of applications, including:  
- Code generation  
- Conversational AI  
- Multi-language adaptation  
- Mental health assistance  
- Reward modeling and preference optimization  
- Reasoning and complex problem solving  
- Efficient inference and deployment  

By following the included Colab notebooks, you'll learn how to:  
âœ… Fine-tune models using lightweight LoRA (Low-Rank Adaptation)  
âœ… Continue pretraining on new datasets  
âœ… Optimize reward signals using ORPO (Online Reward Policy Optimization) and DPO (Direct Preference Optimization)  
âœ… Export models to **Ollama** for production-ready inference  
âœ… Extend context size and improve model reasoning  

---

## âœ… **Assignment Breakdown**  

### **Part A: Finetuning**  
You will finetune various open-weight LLMs using **Unsloth AI** for different tasks:

1. **Llama 3.1 (8B)** â€“ Fine-tuning for a coding task  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-llama3-8b)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-llama3-8b)  
   **Use Case:** Code generation and debugging assistance  

2. **Mistral NeMo (12B)** â€“ Fine-tuning for a chat task  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-mistral-nemo)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-mistral-nemo)  
   **Use Case:** Creating intelligent chatbots for customer support  

3. **Gemma 2 (9B)** â€“ Fine-tuning for a conversational AI task  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-gemma2)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-gemma2)  
   **Use Case:** Natural and human-like dialogue generation  

4. **Phi-3.5 (mini)** â€“ Fine-tuning for a reasoning task  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-phi3-5)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-phi3-5)  
   **Use Case:** Math-based problem-solving and logical reasoning  

---

### **Part B: Continued Pretraining**  
You will use **Unsloth AI** to continue pretraining a model on a new language. This enables the model to:  
âœ… Understand new vocabulary and syntax  
âœ… Improve language translation and understanding  
âœ… Adapt to industry-specific terminology  

- ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-continued-pretraining)  
- ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-continued-pretraining)  
**Use Case:** Training a model to understand domain-specific language (e.g., medical terms, financial language)  

---

### **Part C: Chat Templates**  
Predefined templates for creating various chatbot use cases:  

1. **Classification Chat** â€“ Build a chatbot that can classify user input into predefined categories.  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-classification-chat)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-classification-chat)  
   **Use Case:** Customer query classification  

2. **Conversational Chat** â€“ Develop a chatbot for natural, multi-turn conversations.  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-conversational-chat)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-conversational-chat)  
   **Use Case:** Virtual assistant for customer support  

3. **Context Extension with TinyLlama** â€“ Extend the context size of TinyLlama for handling long conversations or documents.  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-context-extension)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-context-extension)  
   **Use Case:** Long document summarization  

4. **Multi-dataset Single Finetuning** â€“ Finetune on multiple datasets simultaneously for enhanced versatility.  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-multi-dataset)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-multi-dataset)  
   **Use Case:** Cross-domain understanding and adaptation  

---

### **Part D: Reward Modeling**  
Learn how to train LLMs using feedback-based reward models:  

1. **ORPO (Online Reward Policy Optimization)** â€“ Optimize responses in real-time based on user feedback.  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-orpo)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-orpo)  
   **Use Case:** Customer satisfaction feedback loops  

2. **DPO (Direct Preference Optimization)** â€“ Optimize for direct user preferences to enhance response quality.  
   - ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-dpo)  
   - ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-dpo)  
   **Use Case:** Personalization for content recommendations  

---

### **Part E: Continued Fine-Tuning from a Custom Checkpoint**  
Finetune from a custom checkpoint using Unsloth AI.  
- ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-custom-checkpoint)  
- ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-custom-checkpoint)  
**Use Case:** Custom model adaptation for specialized tasks  

---

### **Part F: Mental Health Development Chatbot**  
Finetune **Phi-3** using Unsloth AI to create a mental health chatbot.  
- ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-mental-health-chatbot)  
- ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-mental-health-chatbot)  
**Use Case:** Mental health support and therapy chatbot  

---

### **Part G: Export to Ollama**  
Finetune a model using Unsloth AI and export it to Ollama for efficient inference.  
- ğŸ“„ [Colab Link](https://colab.research.google.com/drive/dummy-link-export-ollama)  
- ğŸ¥ [YouTube Video](https://youtu.be/dummy-link-export-ollama)  
**Use Case:** Fast and scalable model deployment  

---

## ğŸŒŸ **Why This Matters**  
âœ… Speed up training and inference with Unsloth AI  
âœ… Deploy custom models for real-world applications  
âœ… Improve LLM performance with targeted fine-tuning  
âœ… Build production-ready AI systems with scalable deployment options  

**â­ï¸ If you found this helpful, give this repository a star!**  
